{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Imports"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yaml\n",
    "import copy\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification\n",
    "from sqlalchemy import create_engine\n",
    "from sklearn.model_selection import train_test_split\n",
    "from enum import Enum"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Database configuration"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# Reading form config.yaml\"\n",
    "with open(\"../../config.yaml\", \"r\") as yamlconfig:\n",
    "    config = yaml.load(yamlconfig, Loader=yaml.FullLoader)\n",
    "\n",
    "# Create postgres string with db-config\n",
    "postgres_username = config[\"db_config\"][\"postgres_username\"]\n",
    "postgres_password = config[\"db_config\"][\"postgres_password\"]\n",
    "postgres_address = config[\"db_config\"][\"postgres_address\"]\n",
    "postgres_port = config[\"db_config\"][\"postgres_port\"]\n",
    "postgres_dbname = config[\"db_config\"][\"postgres_dbname\"]\n",
    "\n",
    "postgres_str = f\"postgresql://{postgres_username}:{postgres_password}@{postgres_address}:{postgres_port}/{postgres_dbname}\"\n",
    "\n",
    "# create db connection with sqlalchemy\n",
    "cnx = create_engine(postgres_str)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "df = pd.read_sql('SELECT * FROM r_wallstreetbets_stock_symbols LIMIT 100', cnx)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "df['label'] = np.random.choice([1,2,3], df.shape[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "df = df[[\"post\", \"label\"]]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "1    40.0\n3    34.0\n2    26.0\nName: label, dtype: float64"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"label\"].value_counts(normalize=True)*100"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "model_name = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "#model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. Building Pytorch Dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# Make simple Enum for code clarity\n",
    "class DatasetType(Enum):\n",
    "    TRAIN = 1\n",
    "    TEST = 2\n",
    "    # VAL = 3"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "class SentimentAnalysisDataset(Dataset):\n",
    "\n",
    "    def __init__(self,\n",
    "                 df: pd.DataFrame,\n",
    "                 tokenizer: AutoTokenizer,\n",
    "                 max_token_len: int = 512,\n",
    "                 stratify_column_name: str = \"label\",\n",
    "                 frac_train: float = 0.8,\n",
    "                 frac_test: float = 0.2,\n",
    "                 random_state = 42):\n",
    "\n",
    "        self.df = df\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_token_len = max_token_len\n",
    "        self.stratify_column_name = stratify_column_name\n",
    "        self.frac_train = frac_train\n",
    "        self.frac_test = frac_test\n",
    "        self.random_state = random_state\n",
    "\n",
    "        # Initialize dataset and labels as None\n",
    "        self.dataset = None\n",
    "        self.labels = None\n",
    "\n",
    "        # Stratified train_test_split\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = self.stratified_train_test_split()\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.dataset.iloc[idx], self.labels.iloc[idx]\n",
    "\n",
    "    def stratified_train_test_split(self):\n",
    "        X = self.df # Contains all columns.\n",
    "        y = self.df[[self.stratify_column_name]] # Dataframe of just the column on which to stratify.\n",
    "\n",
    "        # Split original dataframe into train and temp dataframes.\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=(1.0 - self.frac_train),random_state=self.random_state)\n",
    "\n",
    "        return X_train, X_test, y_train, y_test\n",
    "\n",
    "    def set_fold(self, type: str):\n",
    "        # It's important to call this method before using the dataset\n",
    "        if type == DatasetType.TRAIN:\n",
    "            self.dataset, self.labels = self.X_train, self.y_train\n",
    "        if type == DatasetType.TEST:\n",
    "            self.dataset, self.labels = self.X_test, self.y_test\n",
    "        return self\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "sentiment_analysis_dataset = SentimentAnalysisDataset(\n",
    "    df = df,\n",
    "    tokenizer = tokenizer\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 31.2 ms\n",
      "Wall time: 28 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train = copy.deepcopy(sentiment_analysis_dataset).set_fold(DatasetType.TRAIN)\n",
    "test = copy.deepcopy(sentiment_analysis_dataset).set_fold(DatasetType.TEST)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "post     Yes, but they're 70 year old boomer dicks at t...\n",
      "label                                                    1\n",
      "Name: 80, dtype: object\n"
     ]
    }
   ],
   "source": [
    "for i in train:\n",
    "    print(i.__getitem__(0))\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "thesis",
   "language": "python",
   "display_name": "thesis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}