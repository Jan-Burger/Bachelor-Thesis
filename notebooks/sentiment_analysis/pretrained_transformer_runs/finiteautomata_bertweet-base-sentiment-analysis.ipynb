{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Imports"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import wandb\n",
    "import copy\n",
    "import torch\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from pytorch_datasets import SentimentAnalysisDataset, DatasetType\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "model_name = \"finiteautomata/bertweet-base-sentiment-analysis\"\n",
    "model_name_wandb = \"finiteautomata_bertweet-base-sentiment-analysis\" # has to be without slash\n",
    "label_arrangement = [\"Negative\", \"Neutral\", \"Positive\"]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Model config"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Load json file with hyperparams of each model\n",
    "with open('../hyperparams.json') as file:\n",
    "    hyper_params = json.load(file)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# Set up Hyper parameters for model training\n",
    "LR: float = hyper_params[model_name][\"lr\"]\n",
    "OPTIMIZER: str = hyper_params[model_name][\"optimizer\"]\n",
    "EPOCHS: int = hyper_params[model_name][\"epochs\"]\n",
    "BATCH_SIZE: int = hyper_params[model_name][\"batch_size\"]\n",
    "DROPOUT: float = hyper_params[model_name][\"dropout\"]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. Dataframe preperations"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"../../../data/wsb_annotations/wsb_annotations_final.xlsx\", sheet_name=\"final_annotations\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "df.drop(columns=[\"stock_symbol\"], inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "2    0.386\n1    0.316\n0    0.298\nName: label, dtype: float64"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"label\"].value_counts(normalize=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. Model Loading"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "#model = AutoModelForSequenceClassification.from_pretrained(model_name, return_dict=True)\n",
    "#tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"finiteautomata/bertweet-base-sentiment-analysis\")\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"finiteautomata/bertweet-base-sentiment-analysis\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "64001"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config.vocab_size"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5. Building Pytorch Dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# Declare generic sentiment analysis dataset without split\n",
    "sentiment_analysis_dataset = SentimentAnalysisDataset(\n",
    "    df = df,\n",
    "    tokenizer = tokenizer,\n",
    "    max_token_len = 128,\n",
    "    label_arrangement = label_arrangement\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# Declare train and test dataset\n",
    "train_dataset = copy.deepcopy(sentiment_analysis_dataset).set_fold(DatasetType.TRAIN)\n",
    "test_dataset = copy.deepcopy(sentiment_analysis_dataset).set_fold(DatasetType.TEST)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# Setup train and test Data loaders\n",
    "train_data_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                                batch_size=BATCH_SIZE,\n",
    "                                                shuffle=True,\n",
    "                                                num_workers=1,\n",
    "                                                drop_last=True\n",
    "                                                )\n",
    "\n",
    "test_data_loader = torch.utils.data.DataLoader(test_dataset,\n",
    "                                              batch_size=BATCH_SIZE,\n",
    "                                              shuffle=False,\n",
    "                                              num_workers=1,\n",
    "                                               drop_last=True\n",
    "                                              )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "800"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.__len__()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "200"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset.__len__()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "TESTING DATA:\n",
      "torch.Size([32, 3])\n"
     ]
    }
   ],
   "source": [
    "# Check if train data and test data have correct batch and tensor sizes\n",
    "\"\"\"print('TRAINING DATA:')\n",
    "for dictionary in train_data_loader:\n",
    "    print(dictionary)\n",
    "    break\"\"\"\n",
    "\n",
    "print(' ')\n",
    "print('TESTING DATA:')\n",
    "for dictionary in test_data_loader:\n",
    "    print(dictionary[\"labels\"].size())\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 7. Model Evaluation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "# pull data from test dataloader to have one batch\n",
    "\n",
    "# labels\n",
    "y_true = torch.cat(tuple(data[\"labels\"] for data in test_data_loader), dim=0).numpy().astype(int)\n",
    "\n",
    "# ids, mask, token_type_ids\n",
    "ids = torch.cat(tuple(data[\"input_ids\"] for data in test_data_loader), dim=0)\n",
    "mask = torch.cat(tuple(data[\"attention_mask\"] for data in test_data_loader), dim=0)\n",
    "token_type_ids = torch.cat(tuple(data[\"token_type_ids\"] for data in test_data_loader), dim=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([    0, 14486,   687,  4886,  1114, 10638,   528, 58098,     3,     2,\n            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n            1,     1,     1,     1,     1,     1,     1,     1])"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [1 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# One last forward pass to evaluate the model\n",
    "with torch.no_grad():\n",
    "    outputs = model(ids, mask, token_type_ids)\n",
    "    y_pred = F.one_hot(torch.argmax(outputs.logits, dim=1), num_classes=3).numpy()\n",
    "    print(y_pred)\n",
    "\n",
    "# need one more epoch before training -> epoch 0\n",
    "# need to save model to wandb or else\n",
    "# get confusion matrices right and lof them to wandb\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "# Calculate accuracy, precision, recall and f1-score with micro average\n",
    "prec_avg = precision_score(y_true=y_true, y_pred=y_pred, average=\"micro\")\n",
    "recall_avg = recall_score(y_true=y_true, y_pred=y_pred, average=\"micro\")\n",
    "f1_avg = f1_score(y_true=y_true, y_pred=y_pred, average=\"micro\")\n",
    "accuracy = (np.argmax(y_pred, axis=1) == np.argmax(y_true, axis=1)).sum() / len(y_pred)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "0.375"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_avg"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "0.375"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.argmax(y_pred, axis=1) == np.argmax(y_true, axis=1)).sum() / len(y_pred)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 8. WANDB Log data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mjan_burger\u001B[0m (\u001B[33mhda_sis\u001B[0m). Use \u001B[1m`wandb login --relogin`\u001B[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "wandb version 0.12.18 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Tracking run with wandb version 0.12.17"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Run data is saved locally in <code>C:\\Users\\janbu\\Desktop\\Bachelor_Thesis\\notebooks\\sentiment_analysis\\pretrained_transformer_runs\\wandb\\run-20220618_200710-h8vyvb7z</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Syncing run <strong><a href=\"https://wandb.ai/hda_sis/Bachelor-Thesis/runs/h8vyvb7z\" target=\"_blank\">ProsusAI_finbert_pretrained</a></strong> to <a href=\"https://wandb.ai/hda_sis/Bachelor-Thesis\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize WAND tracking\n",
    "config = wandb.config = {\n",
    "    \"model_name\": model_name_wandb,\n",
    "    \"type\": \"pretrained model\"\n",
    "}\n",
    "\n",
    "run = wandb.init(project=\"Bachelor-Thesis\", entity=\"hda_sis\", config=config, name=model_name_wandb)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "wandb.log({\"Precision Avg\": prec_avg,\n",
    "           \"Recall Avg\": recall_avg,\n",
    "           \"F1-Score Avg\": f1_avg,\n",
    "           \"Accuracy\": accuracy\n",
    "           })"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "y_true_argmax = np.argmax(y_true, axis=1)\n",
    "y_pred_argmax = np.argmax(y_pred, axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 2 1 0 2 1 0 1 2 0 1 0 1 1 0 2 1 1 0 0 2 1 2 2 2 0 2 1 0 2 0 0 1 2 1 2 2\n",
      " 2 1 0 1 0 2 0 1 1 2 2 1 2 2 2 0 1 2 1 0 0 1 1 0 0 2 1 0 1 0 2 0 0 0 2 0 0\n",
      " 1 0 0 1 1 0 0 0 0 2 1 0 2 0 2 0 0 2 2 0 0 2 0 1 0 2 2 2 0 0 0 0 2 1 0 0 1\n",
      " 0 0 0 1 0 0 0 0 0 2 2 0 2 2 1 1 1 1 1 1 0 1 2 2 2 0 2 0 2 0 1 2 1 2 0 2 1\n",
      " 2 1 1 2 2 1 1 2 0 1 1 1 0 1 0 2 1 1 0 0 2 2 2 2 0 0 0 1 0 1 0 2 1 1 0 1 0\n",
      " 2 1 2 0 2 0 2] [2 0 1 2 2 0 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 1 2 2 2 0 2 2 2 2 0 2 1 2 1 2 1\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 0 2 1 2 1 2 2 1 2 0 2\n",
      " 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 0 1 0 1 2 0 2 2 2 2 2 2 2\n",
      " 2 2 0 1 0 2 2 2 2 2 2 2 1 1 1 2 2 2 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 2 1\n",
      " 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 0 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2\n",
      " 2 1 2 2 2 2 2]\n"
     ]
    }
   ],
   "source": [
    "print(y_true_argmax, y_pred_argmax)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "# Create raw and normalized confusion matrices\n",
    "cm_raw = confusion_matrix(y_true_argmax, y_pred_argmax, labels=[0,1,2])\n",
    "cm_normalized = np.round(cm_raw.astype('float') / cm_raw.sum(axis=1)[:, np.newaxis], decimals=2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ 8,  2, 64],\n       [ 2, 14, 41],\n       [ 3,  8, 50]], dtype=int64)"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm_raw"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.11, 0.03, 0.86],\n       [0.04, 0.25, 0.72],\n       [0.05, 0.13, 0.82]])"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm_normalized"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Plot confusion matrices micro averaged"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 576x360 with 2 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create confusion matrices with seaborn\n",
    "\n",
    "# Raw Confusion matrix\n",
    "df_cm_raw = pd.DataFrame(cm_raw, columns=label_arrangement, index=label_arrangement)\n",
    "df_cm_raw.index.name = \"True label\"\n",
    "df_cm_raw.columns.name = \"Predicted label\"\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.title(f\"Confusion matrix {model_name} - Raw\")\n",
    "plot_cm_raw = sns.heatmap(\n",
    "    df_cm_raw, cmap=\"Blues\", annot=True, annot_kws={\"size\": 14}\n",
    ")  # font size\n",
    "\n",
    "# Log raw confusion matrix to wandb\n",
    "wandb.log({\"Confusion matrix - Raw\": wandb.Image(plot_cm_raw)})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 576x360 with 2 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Normalized Confusion matrix\n",
    "df_cm_norm = pd.DataFrame(cm_normalized, columns=label_arrangement, index=label_arrangement)\n",
    "df_cm_norm.index.name = \"True label\"\n",
    "df_cm_norm.columns.name = \"Predicted label\"\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.title(f\"Confusion matrix {model_name} - Normalized\")\n",
    "plot_cm_norm = sns.heatmap(\n",
    "    df_cm_norm, cmap=\"Blues\", annot=True, annot_kws={\"size\": 14}\n",
    ")  # font size\n",
    "\n",
    "# Log normalized confusion matrix to wandb\n",
    "wandb.log({\"Confusion matrix - Normalized\": wandb.Image(plot_cm_norm)})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "VBox(children=(Label(value='0.031 MB of 0.031 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6159c64ece3e497aaac0b953abca7735"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Accuracy</td><td></td></tr><tr><td>F1-Score Avg</td><td></td></tr><tr><td>Precision Avg</td><td></td></tr><tr><td>Recall Avg</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Accuracy</td><td>0.375</td></tr><tr><td>F1-Score Avg</td><td>0.375</td></tr><tr><td>Precision Avg</td><td>0.375</td></tr><tr><td>Recall Avg</td><td>0.375</td></tr></table><br/></div></div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Synced <strong style=\"color:#cdcd00\">ProsusAI_finbert_pretrained</strong>: <a href=\"https://wandb.ai/hda_sis/Bachelor-Thesis/runs/h8vyvb7z\" target=\"_blank\">https://wandb.ai/hda_sis/Bachelor-Thesis/runs/h8vyvb7z</a><br/>Synced 6 W&B file(s), 2 media file(s), 0 artifact file(s) and 0 other file(s)"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Find logs at: <code>.\\wandb\\run-20220618_200710-h8vyvb7z\\logs</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"finiteautomata/bertweet-base-sentiment-analysis\")\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"finiteautomata/bertweet-base-sentiment-analysis\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "batch = tokenizer([\"Stocks only go up\", \"I love you\", \"I hate you\"], padding=True, truncation=True, max_length=256, return_tensors=\"pt\", add_special_tokens=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "batch = tokenizer.encode_plus(\n",
    "    \"Stocks only go up\",\n",
    "    add_special_tokens=True,\n",
    "    max_length=256,\n",
    "    padding='max_length',\n",
    "    return_token_type_ids=True,\n",
    "    truncation=True,\n",
    "    return_attention_mask=True,\n",
    "    return_tensors='pt'\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "data": {
      "text/plain": "{'input_ids': tensor([[    0, 14659,   121,    82,    49,     2,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SequenceClassifierOutput(loss=None, logits=tensor([[-3.2294,  0.6422,  2.3642]]), hidden_states=None, attentions=None)\n",
      "tensor([[0.0031, 0.1511, 0.8457]])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model(batch[\"input_ids\"], batch[\"attention_mask\"], batch[\"token_type_ids\"])\n",
    "    print(outputs)\n",
    "    predictions = F.softmax(outputs.logits, dim=1)\n",
    "    print(predictions)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1, 256])"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[\"input_ids\"].size()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1, 256])"
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.unsqueeze(ids[0], dim=0).size()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([192, 256])"
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids.size()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index out of range in self",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "Input \u001B[1;32mIn [53]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n\u001B[1;32m----> 2\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mids\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m:\u001B[49m\u001B[38;5;241;43m100\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmask\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m:\u001B[49m\u001B[38;5;241;43m100\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtoken_type_ids\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m:\u001B[49m\u001B[38;5;241;43m100\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      3\u001B[0m     \u001B[38;5;28mprint\u001B[39m(outputs)\n\u001B[0;32m      4\u001B[0m     predictions \u001B[38;5;241m=\u001B[39m F\u001B[38;5;241m.\u001B[39msoftmax(outputs\u001B[38;5;241m.\u001B[39mlogits, dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\thesis\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1106\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1107\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1108\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1109\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1110\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1111\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1112\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\thesis\\lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:1205\u001B[0m, in \u001B[0;36mRobertaForSequenceClassification.forward\u001B[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[0;32m   1197\u001B[0m \u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   1198\u001B[0m \u001B[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001B[39;00m\n\u001B[0;32m   1199\u001B[0m \u001B[38;5;124;03m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001B[39;00m\n\u001B[0;32m   1200\u001B[0m \u001B[38;5;124;03m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001B[39;00m\n\u001B[0;32m   1201\u001B[0m \u001B[38;5;124;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001B[39;00m\n\u001B[0;32m   1202\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   1203\u001B[0m return_dict \u001B[38;5;241m=\u001B[39m return_dict \u001B[38;5;28;01mif\u001B[39;00m return_dict \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39muse_return_dict\n\u001B[1;32m-> 1205\u001B[0m outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mroberta\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1206\u001B[0m \u001B[43m    \u001B[49m\u001B[43minput_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1207\u001B[0m \u001B[43m    \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1208\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtoken_type_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtoken_type_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1209\u001B[0m \u001B[43m    \u001B[49m\u001B[43mposition_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mposition_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1210\u001B[0m \u001B[43m    \u001B[49m\u001B[43mhead_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhead_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1211\u001B[0m \u001B[43m    \u001B[49m\u001B[43minputs_embeds\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs_embeds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1212\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1213\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_hidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1214\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_dict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1215\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1216\u001B[0m sequence_output \u001B[38;5;241m=\u001B[39m outputs[\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m   1217\u001B[0m logits \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclassifier(sequence_output)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\thesis\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1106\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1107\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1108\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1109\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1110\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1111\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1112\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\thesis\\lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:840\u001B[0m, in \u001B[0;36mRobertaModel.forward\u001B[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[0;32m    833\u001B[0m \u001B[38;5;66;03m# Prepare head mask if needed\u001B[39;00m\n\u001B[0;32m    834\u001B[0m \u001B[38;5;66;03m# 1.0 in head_mask indicate we keep the head\u001B[39;00m\n\u001B[0;32m    835\u001B[0m \u001B[38;5;66;03m# attention_probs has shape bsz x n_heads x N x N\u001B[39;00m\n\u001B[0;32m    836\u001B[0m \u001B[38;5;66;03m# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\u001B[39;00m\n\u001B[0;32m    837\u001B[0m \u001B[38;5;66;03m# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\u001B[39;00m\n\u001B[0;32m    838\u001B[0m head_mask \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_head_mask(head_mask, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mnum_hidden_layers)\n\u001B[1;32m--> 840\u001B[0m embedding_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43membeddings\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    841\u001B[0m \u001B[43m    \u001B[49m\u001B[43minput_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minput_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    842\u001B[0m \u001B[43m    \u001B[49m\u001B[43mposition_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mposition_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    843\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtoken_type_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtoken_type_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    844\u001B[0m \u001B[43m    \u001B[49m\u001B[43minputs_embeds\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs_embeds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    845\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpast_key_values_length\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpast_key_values_length\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    846\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    847\u001B[0m encoder_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mencoder(\n\u001B[0;32m    848\u001B[0m     embedding_output,\n\u001B[0;32m    849\u001B[0m     attention_mask\u001B[38;5;241m=\u001B[39mextended_attention_mask,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    857\u001B[0m     return_dict\u001B[38;5;241m=\u001B[39mreturn_dict,\n\u001B[0;32m    858\u001B[0m )\n\u001B[0;32m    859\u001B[0m sequence_output \u001B[38;5;241m=\u001B[39m encoder_outputs[\u001B[38;5;241m0\u001B[39m]\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\thesis\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1106\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1107\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1108\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1109\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1110\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1111\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1112\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\thesis\\lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:133\u001B[0m, in \u001B[0;36mRobertaEmbeddings.forward\u001B[1;34m(self, input_ids, token_type_ids, position_ids, inputs_embeds, past_key_values_length)\u001B[0m\n\u001B[0;32m    131\u001B[0m embeddings \u001B[38;5;241m=\u001B[39m inputs_embeds \u001B[38;5;241m+\u001B[39m token_type_embeddings\n\u001B[0;32m    132\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mposition_embedding_type \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mabsolute\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m--> 133\u001B[0m     position_embeddings \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mposition_embeddings\u001B[49m\u001B[43m(\u001B[49m\u001B[43mposition_ids\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    134\u001B[0m     embeddings \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m position_embeddings\n\u001B[0;32m    135\u001B[0m embeddings \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mLayerNorm(embeddings)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\thesis\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1106\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1107\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1108\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1109\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1110\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1111\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1112\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\thesis\\lib\\site-packages\\torch\\nn\\modules\\sparse.py:158\u001B[0m, in \u001B[0;36mEmbedding.forward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    157\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[1;32m--> 158\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43membedding\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    159\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpadding_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmax_norm\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    160\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnorm_type\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mscale_grad_by_freq\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msparse\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\thesis\\lib\\site-packages\\torch\\nn\\functional.py:2183\u001B[0m, in \u001B[0;36membedding\u001B[1;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001B[0m\n\u001B[0;32m   2177\u001B[0m     \u001B[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001B[39;00m\n\u001B[0;32m   2178\u001B[0m     \u001B[38;5;66;03m# XXX: equivalent to\u001B[39;00m\n\u001B[0;32m   2179\u001B[0m     \u001B[38;5;66;03m# with torch.no_grad():\u001B[39;00m\n\u001B[0;32m   2180\u001B[0m     \u001B[38;5;66;03m#   torch.embedding_renorm_\u001B[39;00m\n\u001B[0;32m   2181\u001B[0m     \u001B[38;5;66;03m# remove once script supports set_grad_enabled\u001B[39;00m\n\u001B[0;32m   2182\u001B[0m     _no_grad_embedding_renorm_(weight, \u001B[38;5;28minput\u001B[39m, max_norm, norm_type)\n\u001B[1;32m-> 2183\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43membedding\u001B[49m\u001B[43m(\u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpadding_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mscale_grad_by_freq\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msparse\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mIndexError\u001B[0m: index out of range in self"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model(ids[0:100], mask[0:100], token_type_ids[0:100])\n",
    "    print(outputs)\n",
    "    predictions = F.softmax(outputs.logits, dim=1)\n",
    "    print(predictions)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,  6630,  1061,  9731,     4,   180,    25,  4754,  5946,    86,\n",
      "            31,   226,  6002,    30, 19302, 22717, 24236,  2124,   520,     7,\n",
      "           367,    52, 17869,   634,  2463, 33271,  2416,  1928,  7242,  2857,\n",
      "             9,  2084,  6377, 32188,  4852,    43, 42325,   783,  2603, 15402,\n",
      "           471, 15026,   256,    86,    31,    11,    94,  1470,   137,   133,\n",
      "          7204, 17869, 19302, 22717,    16,  4527,    52,    14,  5748, 23836,\n",
      "             3,  5368,  5368,   906, 16616, 21654,  1554,  1043,     3,   205,\n",
      "         48425, 34287,     9, 37008,   268, 14058,   685, 18296,     7, 39397,\n",
      "            13,  6519,   879,     7,    32,    14,   169,     6,  1329, 43964,\n",
      "            20,  9327,   527, 10994,    48, 11787, 42747, 53058,   423,    60,\n",
      "            72,    17,    18,  4548, 35530, 38370,  1250,   208,    19, 14317,\n",
      "           121, 19295,   836,   543, 17742,   612,  1364,   429,  3582,  1847,\n",
      "         50239, 50239,     3,   458,  5664, 32059,   856,     7, 37303,  9570,\n",
      "          8852,  2603,  5830,  3799,   865,    78,     8,   129,  1601,    84,\n",
      "          3805,   224,  2002,   268, 32097,   384,   109,  2505,    15,  5946,\n",
      "            16,    33,  2505,    15,  7122,     4,  1373,    14, 22979,    11,\n",
      "           263, 25392,    21,     2,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1]])\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=torch.int32)\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    for i in range(len(ids)):\n",
    "        outputs = model(torch.unsqueeze(ids[i], dim=0),\n",
    "                        torch.unsqueeze(mask[i], dim=0),\n",
    "                        torch.unsqueeze(token_type_ids[i], dim=0))\n",
    "except Exception as e:\n",
    "    print(torch.unsqueeze(ids[i], dim=0))\n",
    "    print(torch.unsqueeze(mask[i], dim=0))\n",
    "    print(torch.unsqueeze(token_type_ids[i], dim=0))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(53058)"
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(ids[i])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [
    {
     "data": {
      "text/plain": "RobertaConfig {\n  \"_name_or_path\": \"finiteautomata/bertweet-base-sentiment-analysis\",\n  \"architectures\": [\n    \"RobertaForSequenceClassification\"\n  ],\n  \"attention_probs_dropout_prob\": 0.1,\n  \"bos_token_id\": 0,\n  \"classifier_dropout\": null,\n  \"eos_token_id\": 2,\n  \"gradient_checkpointing\": false,\n  \"hidden_act\": \"gelu\",\n  \"hidden_dropout_prob\": 0.1,\n  \"hidden_size\": 768,\n  \"id2label\": {\n    \"0\": \"NEG\",\n    \"1\": \"NEU\",\n    \"2\": \"POS\"\n  },\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 3072,\n  \"label2id\": {\n    \"NEG\": 0,\n    \"NEU\": 1,\n    \"POS\": 2\n  },\n  \"layer_norm_eps\": 1e-05,\n  \"max_position_embeddings\": 130,\n  \"model_type\": \"roberta\",\n  \"num_attention_heads\": 12,\n  \"num_hidden_layers\": 12,\n  \"pad_token_id\": 1,\n  \"position_embedding_type\": \"absolute\",\n  \"problem_type\": \"single_label_classification\",\n  \"tokenizer_class\": \"BertweetTokenizer\",\n  \"transformers_version\": \"4.19.2\",\n  \"type_vocab_size\": 1,\n  \"use_cache\": true,\n  \"vocab_size\": 64001\n}"
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}