{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Imports"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "import wandb\n",
    "import copy\n",
    "import torch\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, RobertaConfig\n",
    "from pytorch_datasets import SentimentAnalysisDataset, DatasetType\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "model_name = \"finiteautomata/bertweet-base-sentiment-analysis\"\n",
    "model_name_wandb = \"finiteautomata_bertweet-base-sentiment-analysis\" # has to be without slash\n",
    "label_arrangement = [\"Negative\", \"Neutral\", \"Positive\"]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Model config"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Load json file with hyperparams of each model\n",
    "with open('../hyperparams.json') as file:\n",
    "    hyper_params = json.load(file)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# Set up Hyper parameters for model training\n",
    "LR: float = hyper_params[model_name][\"lr\"]\n",
    "OPTIMIZER: str = hyper_params[model_name][\"optimizer\"]\n",
    "EPOCHS: int = hyper_params[model_name][\"epochs\"]\n",
    "BATCH_SIZE: int = hyper_params[model_name][\"batch_size\"]\n",
    "DROPOUT: float = hyper_params[model_name][\"dropout\"]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. Dataframe preperations"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"../../../data/wsb_annotations/wsb_annotations_final.xlsx\", sheet_name=\"final_annotations\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "df.drop(columns=[\"stock_symbol\"], inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "2    0.386\n1    0.316\n0    0.298\nName: label, dtype: float64"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"label\"].value_counts(normalize=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. Model Loading"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "#model = AutoModelForSequenceClassification.from_pretrained(model_name, return_dict=True)\n",
    "#tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"finiteautomata/bertweet-base-sentiment-analysis\")\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"finiteautomata/bertweet-base-sentiment-analysis\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "64001"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config.vocab_size"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5. Building Pytorch Dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "# Declare generic sentiment analysis dataset without split\n",
    "sentiment_analysis_dataset = SentimentAnalysisDataset(\n",
    "    df = df,\n",
    "    tokenizer = tokenizer,\n",
    "    max_token_len = 128,\n",
    "    label_arrangement = label_arrangement\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "# Declare train and test dataset\n",
    "train_dataset = copy.deepcopy(sentiment_analysis_dataset).set_fold(DatasetType.TRAIN)\n",
    "test_dataset = copy.deepcopy(sentiment_analysis_dataset).set_fold(DatasetType.TEST)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "# Setup train and test Data loaders\n",
    "train_data_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                                batch_size=BATCH_SIZE,\n",
    "                                                shuffle=True,\n",
    "                                                num_workers=1,\n",
    "                                                drop_last=True\n",
    "                                                )\n",
    "\n",
    "test_data_loader = torch.utils.data.DataLoader(test_dataset,\n",
    "                                              batch_size=BATCH_SIZE,\n",
    "                                              shuffle=False,\n",
    "                                              num_workers=1,\n",
    "                                               drop_last=True\n",
    "                                              )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "800"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.__len__()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "200"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset.__len__()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "TESTING DATA:\n",
      "torch.Size([32, 3])\n"
     ]
    }
   ],
   "source": [
    "# Check if train data and test data have correct batch and tensor sizes\n",
    "\"\"\"print('TRAINING DATA:')\n",
    "for dictionary in train_data_loader:\n",
    "    print(dictionary)\n",
    "    break\"\"\"\n",
    "\n",
    "print(' ')\n",
    "print('TESTING DATA:')\n",
    "for dictionary in test_data_loader:\n",
    "    print(dictionary[\"labels\"].size())\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 7. Model Evaluation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "# pull data from test dataloader to have one batch\n",
    "\n",
    "# labels\n",
    "y_true = torch.cat(tuple(data[\"labels\"] for data in test_data_loader), dim=0).numpy().astype(int)\n",
    "\n",
    "# ids, mask, token_type_ids\n",
    "ids = torch.cat(tuple(data[\"input_ids\"] for data in test_data_loader), dim=0)\n",
    "mask = torch.cat(tuple(data[\"attention_mask\"] for data in test_data_loader), dim=0)\n",
    "token_type_ids = torch.cat(tuple(data[\"token_type_ids\"] for data in test_data_loader), dim=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([    0, 14486,   687,  4886,  1114, 10638,   528, 58098,     3,     2,\n            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n            1,     1,     1,     1,     1,     1,     1,     1])"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [1 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# One last forward pass to evaluate the model\n",
    "with torch.no_grad():\n",
    "    outputs = model(ids, mask, token_type_ids)\n",
    "    y_pred = F.one_hot(torch.argmax(outputs.logits, dim=1), num_classes=3).numpy()\n",
    "    print(y_pred)\n",
    "\n",
    "# need one more epoch before training -> epoch 0\n",
    "# need to save model to wandb or else\n",
    "# get confusion matrices right and lof them to wandb\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "# Calculate accuracy, precision, recall and f1-score with micro average\n",
    "prec_avg = precision_score(y_true=y_true, y_pred=y_pred, average=\"micro\")\n",
    "recall_avg = recall_score(y_true=y_true, y_pred=y_pred, average=\"micro\")\n",
    "f1_avg = f1_score(y_true=y_true, y_pred=y_pred, average=\"micro\")\n",
    "accuracy = (np.argmax(y_pred, axis=1) == np.argmax(y_true, axis=1)).sum() / len(y_pred)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "0.4635416666666667"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_avg"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "0.4635416666666667"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.argmax(y_pred, axis=1) == np.argmax(y_true, axis=1)).sum() / len(y_pred)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 8. WANDB Log data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mjan_burger\u001B[0m (\u001B[33mhda_sis\u001B[0m). Use \u001B[1m`wandb login --relogin`\u001B[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "wandb version 0.12.18 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Tracking run with wandb version 0.12.17"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Run data is saved locally in <code>C:\\Users\\janbu\\Desktop\\Bachelor_Thesis\\notebooks\\sentiment_analysis\\pretrained_transformer_runs\\wandb\\run-20220619_091142-3jxn5g6t</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Syncing run <strong><a href=\"https://wandb.ai/hda_sis/Bachelor-Thesis/runs/3jxn5g6t\" target=\"_blank\">finiteautomata_bertweet-base-sentiment-analysis</a></strong> to <a href=\"https://wandb.ai/hda_sis/Bachelor-Thesis\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize WAND tracking\n",
    "config = wandb.config = {\n",
    "    \"model_name\": model_name_wandb,\n",
    "    \"type\": \"pretrained model\"\n",
    "}\n",
    "\n",
    "run = wandb.init(project=\"Bachelor-Thesis\", entity=\"hda_sis\", config=config, name=model_name_wandb)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "wandb.log({\"Precision Avg\": prec_avg,\n",
    "           \"Recall Avg\": recall_avg,\n",
    "           \"F1-Score Avg\": f1_avg,\n",
    "           \"Accuracy\": accuracy\n",
    "           })"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "y_true_argmax = np.argmax(y_true, axis=1)\n",
    "y_pred_argmax = np.argmax(y_pred, axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 0 2 1 0 2 0 1 2 0 2 0 0 2 1 0 0 2 2 1 0 1 1 1 2 1 0 2 1 2 2 0 1 0 1 1\n",
      " 1 0 2 0 2 1 2 0 0 1 1 0 1 1 1 2 0 1 0 2 2 0 0 2 2 1 0 2 0 2 1 2 2 2 1 2 2\n",
      " 0 2 2 0 0 2 2 2 2 1 0 2 1 2 1 2 2 1 1 2 2 1 2 0 2 1 1 1 2 2 2 2 1 0 2 2 0\n",
      " 2 2 2 0 2 2 2 2 2 1 1 2 1 1 0 0 0 0 0 0 2 0 1 1 1 2 1 2 1 2 0 1 0 1 2 1 0\n",
      " 1 0 0 1 1 0 0 1 2 0 0 0 2 0 2 1 0 0 2 2 1 1 1 1 2 2 2 0 2 0 2 1 0 0 2 0 2\n",
      " 1 0 1 2 1 2 1] [1 1 0 1 1 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 1 0 1 0 0 2 1 1 2 1 2 1 1 1 0 1 0\n",
      " 1 0 1 1 1 1 1 1 0 1 0 0 1 0 0 1 1 1 0 2 1 0 0 1 1 0 2 0 0 1 0 1 2 1 1 2 2\n",
      " 1 1 0 0 1 1 0 1 0 1 0 1 1 2 1 1 0 1 1 1 0 1 2 1 2 2 1 0 0 1 1 2 1 1 0 1 1\n",
      " 1 0 2 0 1 0 1 1 1 1 1 0 0 0 0 1 0 1 1 0 1 0 0 0 1 1 1 2 1 0 1 1 1 1 2 1 0\n",
      " 0 0 0 0 0 0 1 0 2 0 0 0 2 0 1 1 1 2 2 1 0 1 0 0 1 2 1 1 1 1 1 0 0 0 2 0 1\n",
      " 0 0 1 0 0 2 0]\n"
     ]
    }
   ],
   "source": [
    "print(y_true_argmax, y_pred_argmax)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "# Create raw and normalized confusion matrices\n",
    "cm_raw = confusion_matrix(y_true_argmax, y_pred_argmax, labels=[0,1,2])\n",
    "cm_normalized = np.round(cm_raw.astype('float') / cm_raw.sum(axis=1)[:, np.newaxis], decimals=2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[35, 20,  2],\n       [26, 34,  1],\n       [17, 37, 20]], dtype=int64)"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm_raw"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.61, 0.35, 0.04],\n       [0.43, 0.56, 0.02],\n       [0.23, 0.5 , 0.27]])"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm_normalized"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Plot confusion matrices micro averaged"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 576x360 with 2 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create confusion matrices with seaborn\n",
    "\n",
    "# Raw Confusion matrix\n",
    "df_cm_raw = pd.DataFrame(cm_raw, columns=label_arrangement, index=label_arrangement)\n",
    "df_cm_raw.index.name = \"True label\"\n",
    "df_cm_raw.columns.name = \"Predicted label\"\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.title(f\"Confusion matrix {model_name} - Raw\")\n",
    "plot_cm_raw = sns.heatmap(\n",
    "    df_cm_raw, cmap=\"Blues\", annot=True, annot_kws={\"size\": 14}\n",
    ")  # font size\n",
    "\n",
    "# Log raw confusion matrix to wandb\n",
    "wandb.log({\"Confusion matrix - Raw\": wandb.Image(plot_cm_raw)})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 576x360 with 2 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Normalized Confusion matrix\n",
    "df_cm_norm = pd.DataFrame(cm_normalized, columns=label_arrangement, index=label_arrangement)\n",
    "df_cm_norm.index.name = \"True label\"\n",
    "df_cm_norm.columns.name = \"Predicted label\"\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.title(f\"Confusion matrix {model_name} - Normalized\")\n",
    "plot_cm_norm = sns.heatmap(\n",
    "    df_cm_norm, cmap=\"Blues\", annot=True, annot_kws={\"size\": 14}\n",
    ")  # font size\n",
    "\n",
    "# Log normalized confusion matrix to wandb\n",
    "wandb.log({\"Confusion matrix - Normalized\": wandb.Image(plot_cm_norm)})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "VBox(children=(Label(value='0.034 MB of 0.034 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "525d6f5df8234667877b4351654aa495"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Accuracy</td><td>▁</td></tr><tr><td>F1-Score Avg</td><td>▁</td></tr><tr><td>Precision Avg</td><td>▁</td></tr><tr><td>Recall Avg</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Accuracy</td><td>0.46354</td></tr><tr><td>F1-Score Avg</td><td>0.46354</td></tr><tr><td>Precision Avg</td><td>0.46354</td></tr><tr><td>Recall Avg</td><td>0.46354</td></tr></table><br/></div></div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Synced <strong style=\"color:#cdcd00\">finiteautomata_bertweet-base-sentiment-analysis</strong>: <a href=\"https://wandb.ai/hda_sis/Bachelor-Thesis/runs/3jxn5g6t\" target=\"_blank\">https://wandb.ai/hda_sis/Bachelor-Thesis/runs/3jxn5g6t</a><br/>Synced 6 W&B file(s), 2 media file(s), 0 artifact file(s) and 0 other file(s)"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Find logs at: <code>.\\wandb\\run-20220619_091142-3jxn5g6t\\logs</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"finiteautomata/bertweet-base-sentiment-analysis\")\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"finiteautomata/bertweet-base-sentiment-analysis\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "batch = tokenizer([\"Stocks only go up\", \"I love you\", \"I hate you\"], padding=True, truncation=True, max_length=256, return_tensors=\"pt\", add_special_tokens=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "batch = tokenizer.encode_plus(\n",
    "    \"Stocks only go up\",\n",
    "    add_special_tokens=True,\n",
    "    max_length=256,\n",
    "    padding='max_length',\n",
    "    return_token_type_ids=True,\n",
    "    truncation=True,\n",
    "    return_attention_mask=True,\n",
    "    return_tensors='pt'\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "data": {
      "text/plain": "{'input_ids': tensor([[    0, 14659,   121,    82,    49,     2,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SequenceClassifierOutput(loss=None, logits=tensor([[-3.2294,  0.6422,  2.3642]]), hidden_states=None, attentions=None)\n",
      "tensor([[0.0031, 0.1511, 0.8457]])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model(batch[\"input_ids\"], batch[\"attention_mask\"], batch[\"token_type_ids\"])\n",
    "    print(outputs)\n",
    "    predictions = F.softmax(outputs.logits, dim=1)\n",
    "    print(predictions)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1, 256])"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[\"input_ids\"].size()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1, 256])"
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.unsqueeze(ids[0], dim=0).size()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([192, 256])"
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids.size()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index out of range in self",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "Input \u001B[1;32mIn [53]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n\u001B[1;32m----> 2\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mids\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m:\u001B[49m\u001B[38;5;241;43m100\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmask\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m:\u001B[49m\u001B[38;5;241;43m100\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtoken_type_ids\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m:\u001B[49m\u001B[38;5;241;43m100\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      3\u001B[0m     \u001B[38;5;28mprint\u001B[39m(outputs)\n\u001B[0;32m      4\u001B[0m     predictions \u001B[38;5;241m=\u001B[39m F\u001B[38;5;241m.\u001B[39msoftmax(outputs\u001B[38;5;241m.\u001B[39mlogits, dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\thesis\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1106\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1107\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1108\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1109\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1110\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1111\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1112\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\thesis\\lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:1205\u001B[0m, in \u001B[0;36mRobertaForSequenceClassification.forward\u001B[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[0;32m   1197\u001B[0m \u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   1198\u001B[0m \u001B[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001B[39;00m\n\u001B[0;32m   1199\u001B[0m \u001B[38;5;124;03m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001B[39;00m\n\u001B[0;32m   1200\u001B[0m \u001B[38;5;124;03m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001B[39;00m\n\u001B[0;32m   1201\u001B[0m \u001B[38;5;124;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001B[39;00m\n\u001B[0;32m   1202\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   1203\u001B[0m return_dict \u001B[38;5;241m=\u001B[39m return_dict \u001B[38;5;28;01mif\u001B[39;00m return_dict \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39muse_return_dict\n\u001B[1;32m-> 1205\u001B[0m outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mroberta\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1206\u001B[0m \u001B[43m    \u001B[49m\u001B[43minput_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1207\u001B[0m \u001B[43m    \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1208\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtoken_type_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtoken_type_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1209\u001B[0m \u001B[43m    \u001B[49m\u001B[43mposition_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mposition_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1210\u001B[0m \u001B[43m    \u001B[49m\u001B[43mhead_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhead_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1211\u001B[0m \u001B[43m    \u001B[49m\u001B[43minputs_embeds\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs_embeds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1212\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1213\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_hidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1214\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_dict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1215\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1216\u001B[0m sequence_output \u001B[38;5;241m=\u001B[39m outputs[\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m   1217\u001B[0m logits \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclassifier(sequence_output)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\thesis\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1106\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1107\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1108\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1109\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1110\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1111\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1112\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\thesis\\lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:840\u001B[0m, in \u001B[0;36mRobertaModel.forward\u001B[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[0;32m    833\u001B[0m \u001B[38;5;66;03m# Prepare head mask if needed\u001B[39;00m\n\u001B[0;32m    834\u001B[0m \u001B[38;5;66;03m# 1.0 in head_mask indicate we keep the head\u001B[39;00m\n\u001B[0;32m    835\u001B[0m \u001B[38;5;66;03m# attention_probs has shape bsz x n_heads x N x N\u001B[39;00m\n\u001B[0;32m    836\u001B[0m \u001B[38;5;66;03m# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\u001B[39;00m\n\u001B[0;32m    837\u001B[0m \u001B[38;5;66;03m# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\u001B[39;00m\n\u001B[0;32m    838\u001B[0m head_mask \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_head_mask(head_mask, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mnum_hidden_layers)\n\u001B[1;32m--> 840\u001B[0m embedding_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43membeddings\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    841\u001B[0m \u001B[43m    \u001B[49m\u001B[43minput_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minput_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    842\u001B[0m \u001B[43m    \u001B[49m\u001B[43mposition_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mposition_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    843\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtoken_type_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtoken_type_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    844\u001B[0m \u001B[43m    \u001B[49m\u001B[43minputs_embeds\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs_embeds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    845\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpast_key_values_length\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpast_key_values_length\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    846\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    847\u001B[0m encoder_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mencoder(\n\u001B[0;32m    848\u001B[0m     embedding_output,\n\u001B[0;32m    849\u001B[0m     attention_mask\u001B[38;5;241m=\u001B[39mextended_attention_mask,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    857\u001B[0m     return_dict\u001B[38;5;241m=\u001B[39mreturn_dict,\n\u001B[0;32m    858\u001B[0m )\n\u001B[0;32m    859\u001B[0m sequence_output \u001B[38;5;241m=\u001B[39m encoder_outputs[\u001B[38;5;241m0\u001B[39m]\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\thesis\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1106\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1107\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1108\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1109\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1110\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1111\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1112\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\thesis\\lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:133\u001B[0m, in \u001B[0;36mRobertaEmbeddings.forward\u001B[1;34m(self, input_ids, token_type_ids, position_ids, inputs_embeds, past_key_values_length)\u001B[0m\n\u001B[0;32m    131\u001B[0m embeddings \u001B[38;5;241m=\u001B[39m inputs_embeds \u001B[38;5;241m+\u001B[39m token_type_embeddings\n\u001B[0;32m    132\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mposition_embedding_type \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mabsolute\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m--> 133\u001B[0m     position_embeddings \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mposition_embeddings\u001B[49m\u001B[43m(\u001B[49m\u001B[43mposition_ids\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    134\u001B[0m     embeddings \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m position_embeddings\n\u001B[0;32m    135\u001B[0m embeddings \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mLayerNorm(embeddings)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\thesis\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1106\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1107\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1108\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1109\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1110\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1111\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1112\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\thesis\\lib\\site-packages\\torch\\nn\\modules\\sparse.py:158\u001B[0m, in \u001B[0;36mEmbedding.forward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    157\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[1;32m--> 158\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43membedding\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    159\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpadding_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmax_norm\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    160\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnorm_type\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mscale_grad_by_freq\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msparse\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\thesis\\lib\\site-packages\\torch\\nn\\functional.py:2183\u001B[0m, in \u001B[0;36membedding\u001B[1;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001B[0m\n\u001B[0;32m   2177\u001B[0m     \u001B[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001B[39;00m\n\u001B[0;32m   2178\u001B[0m     \u001B[38;5;66;03m# XXX: equivalent to\u001B[39;00m\n\u001B[0;32m   2179\u001B[0m     \u001B[38;5;66;03m# with torch.no_grad():\u001B[39;00m\n\u001B[0;32m   2180\u001B[0m     \u001B[38;5;66;03m#   torch.embedding_renorm_\u001B[39;00m\n\u001B[0;32m   2181\u001B[0m     \u001B[38;5;66;03m# remove once script supports set_grad_enabled\u001B[39;00m\n\u001B[0;32m   2182\u001B[0m     _no_grad_embedding_renorm_(weight, \u001B[38;5;28minput\u001B[39m, max_norm, norm_type)\n\u001B[1;32m-> 2183\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43membedding\u001B[49m\u001B[43m(\u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpadding_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mscale_grad_by_freq\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msparse\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mIndexError\u001B[0m: index out of range in self"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model(ids[0:100], mask[0:100], token_type_ids[0:100])\n",
    "    print(outputs)\n",
    "    predictions = F.softmax(outputs.logits, dim=1)\n",
    "    print(predictions)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,  6630,  1061,  9731,     4,   180,    25,  4754,  5946,    86,\n",
      "            31,   226,  6002,    30, 19302, 22717, 24236,  2124,   520,     7,\n",
      "           367,    52, 17869,   634,  2463, 33271,  2416,  1928,  7242,  2857,\n",
      "             9,  2084,  6377, 32188,  4852,    43, 42325,   783,  2603, 15402,\n",
      "           471, 15026,   256,    86,    31,    11,    94,  1470,   137,   133,\n",
      "          7204, 17869, 19302, 22717,    16,  4527,    52,    14,  5748, 23836,\n",
      "             3,  5368,  5368,   906, 16616, 21654,  1554,  1043,     3,   205,\n",
      "         48425, 34287,     9, 37008,   268, 14058,   685, 18296,     7, 39397,\n",
      "            13,  6519,   879,     7,    32,    14,   169,     6,  1329, 43964,\n",
      "            20,  9327,   527, 10994,    48, 11787, 42747, 53058,   423,    60,\n",
      "            72,    17,    18,  4548, 35530, 38370,  1250,   208,    19, 14317,\n",
      "           121, 19295,   836,   543, 17742,   612,  1364,   429,  3582,  1847,\n",
      "         50239, 50239,     3,   458,  5664, 32059,   856,     7, 37303,  9570,\n",
      "          8852,  2603,  5830,  3799,   865,    78,     8,   129,  1601,    84,\n",
      "          3805,   224,  2002,   268, 32097,   384,   109,  2505,    15,  5946,\n",
      "            16,    33,  2505,    15,  7122,     4,  1373,    14, 22979,    11,\n",
      "           263, 25392,    21,     2,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1]])\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=torch.int32)\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    for i in range(len(ids)):\n",
    "        outputs = model(torch.unsqueeze(ids[i], dim=0),\n",
    "                        torch.unsqueeze(mask[i], dim=0),\n",
    "                        torch.unsqueeze(token_type_ids[i], dim=0))\n",
    "except Exception as e:\n",
    "    print(torch.unsqueeze(ids[i], dim=0))\n",
    "    print(torch.unsqueeze(mask[i], dim=0))\n",
    "    print(torch.unsqueeze(token_type_ids[i], dim=0))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(53058)"
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(ids[i])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [
    {
     "data": {
      "text/plain": "RobertaConfig {\n  \"_name_or_path\": \"finiteautomata/bertweet-base-sentiment-analysis\",\n  \"architectures\": [\n    \"RobertaForSequenceClassification\"\n  ],\n  \"attention_probs_dropout_prob\": 0.1,\n  \"bos_token_id\": 0,\n  \"classifier_dropout\": null,\n  \"eos_token_id\": 2,\n  \"gradient_checkpointing\": false,\n  \"hidden_act\": \"gelu\",\n  \"hidden_dropout_prob\": 0.1,\n  \"hidden_size\": 768,\n  \"id2label\": {\n    \"0\": \"NEG\",\n    \"1\": \"NEU\",\n    \"2\": \"POS\"\n  },\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 3072,\n  \"label2id\": {\n    \"NEG\": 0,\n    \"NEU\": 1,\n    \"POS\": 2\n  },\n  \"layer_norm_eps\": 1e-05,\n  \"max_position_embeddings\": 130,\n  \"model_type\": \"roberta\",\n  \"num_attention_heads\": 12,\n  \"num_hidden_layers\": 12,\n  \"pad_token_id\": 1,\n  \"position_embedding_type\": \"absolute\",\n  \"problem_type\": \"single_label_classification\",\n  \"tokenizer_class\": \"BertweetTokenizer\",\n  \"transformers_version\": \"4.19.2\",\n  \"type_vocab_size\": 1,\n  \"use_cache\": true,\n  \"vocab_size\": 64001\n}"
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}